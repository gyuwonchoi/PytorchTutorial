{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuickStart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMciICKZxIqNIUo+K58AW+b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyuwonchoi/PytorchTutorial/blob/main/QuickStart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fDPWSL7eJzy_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets                # especially for vision \n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=datasets.FashionMNIST(            # module from torchvision\n",
        "    root='data',                                # download path \n",
        "    train=True,                                 # differs the data set (train-images-idx3-ubyte, otherwise from t10k-images-idx3-ubyte.) : later one for test \n",
        "    download=True,                              # whether download or not\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "ZcfuBUiiN-k6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=datasets.FashionMNIST(            # module from torchvision\n",
        "    root='data',                            # download path \n",
        "    train=False,                            # t10k-images-idx3-ubyte : later one for test \n",
        "    download=True,                          # whether download or not\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "TNufNRZAOInS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# create dataloader from torch.utils.data module\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)  # dataset => mini batch \n",
        "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")                     # f for fromatting \n",
        "    print(f\"Shape of y: {y.shape}/{y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVSf1i-WPstB",
        "outputId": "010084fc-308a-42a6-fcdf-44fa9607d820"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64])/torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# define model\n",
        "class NeuralNetwork(nn.Module):        # nn module from torch \n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()        # Replace nn.Flattne() format to self.flatten: use when you make new instance\n",
        "                                       # Instantiating a class: creating a copy of the class which inherits all class variables and methods.\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),         # not 28,28 but 784\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)             # 10 classes , error code: out_features: used . (should be ,)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "      x = self.flatten(x)             \n",
        "      logits= self.linear_relu_stack(x)\n",
        "      return logits\n",
        "\n",
        "model= NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbMKovbPP3VR",
        "outputId": "99f16efe-c061-4120-93b4-e8ace600ab40"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "iqOfjmJjeubL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()  # softmax + cross entropy : you dont need to add softmax at the end of model\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "jw5pUWcYezeb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Training "
      ],
      "metadata": {
        "id": "bf4fXyiNfiTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)      #  total training data size \n",
        "\n",
        "  test_loss, correct = 0,0\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)   # copy all the tensor variables at the beginning of reading data to the GPU\n",
        "                                          # declare variable also\n",
        "        \n",
        "  # error from predictec result \n",
        "      pred = model(X)\n",
        "      loss = loss_func(pred, y)\n",
        "     \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        loss, current = loss.item(), batch*len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "BKW4CuIffQHT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size=len(dataloader.dataset)\n",
        "  num_batches= len(dataloader)\n",
        "  model.eval()\n",
        "\n",
        "  test_loss, correct =0,0\n",
        "\n",
        "  with torch.no_grad(): # because it is test time\n",
        "    for X, y in dataloader: # in batch \n",
        "        X, y = X.to(device), y.to(device) # to GPU\n",
        "        pred=model(X)   # forward propa\n",
        " \n",
        "        test_loss+= loss_func(pred,y).item() # if reduction is true of nn.CrossEntropyLoss(), its output is scalar or same as input \n",
        "                                             # loss btw 2 probabilities \n",
        "        correct+= (pred.argmax(1) == y).type(torch.float).sum().item() # y is G.T, \n",
        "                                                                       # output : prob of each class : vector\n",
        "        #print((pred.argmax(1) == y).type(torch.float).sum()) # every 10 scores of each img \n",
        "                                                              # dimen 1 for row-wise \n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ],
      "metadata": {
        "id": "auL-ZepWJWPB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 5\n",
        "\n",
        "for t in range(5):\n",
        "    train(train_dataloader, model, loss_func, optimizer)\n",
        "    test(test_dataloader, model, loss_func)\n",
        "  \n",
        "print(\"done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onbys5KSWQte",
        "outputId": "b42c1f14-df71-46ff-de23-754c791898cb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 1.153190  [    0/60000]\n",
            "loss: 1.149499  [ 6400/60000]\n",
            "loss: 0.975585  [12800/60000]\n",
            "loss: 1.100361  [19200/60000]\n",
            "loss: 0.981066  [25600/60000]\n",
            "loss: 1.014883  [32000/60000]\n",
            "loss: 1.047661  [38400/60000]\n",
            "loss: 0.992606  [44800/60000]\n",
            "loss: 1.026445  [51200/60000]\n",
            "loss: 0.950011  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.7%, Avg loss: 0.972744 \n",
            "\n",
            "loss: 1.037337  [    0/60000]\n",
            "loss: 1.054595  [ 6400/60000]\n",
            "loss: 0.864105  [12800/60000]\n",
            "loss: 1.011716  [19200/60000]\n",
            "loss: 0.898545  [25600/60000]\n",
            "loss: 0.923932  [32000/60000]\n",
            "loss: 0.973794  [38400/60000]\n",
            "loss: 0.921687  [44800/60000]\n",
            "loss: 0.950693  [51200/60000]\n",
            "loss: 0.885989  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.2%, Avg loss: 0.903523 \n",
            "\n",
            "loss: 0.953239  [    0/60000]\n",
            "loss: 0.989826  [ 6400/60000]\n",
            "loss: 0.785194  [12800/60000]\n",
            "loss: 0.949126  [19200/60000]\n",
            "loss: 0.843428  [25600/60000]\n",
            "loss: 0.857911  [32000/60000]\n",
            "loss: 0.921763  [38400/60000]\n",
            "loss: 0.874444  [44800/60000]\n",
            "loss: 0.896027  [51200/60000]\n",
            "loss: 0.839938  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.2%, Avg loss: 0.853645 \n",
            "\n",
            "loss: 0.888670  [    0/60000]\n",
            "loss: 0.941746  [ 6400/60000]\n",
            "loss: 0.726266  [12800/60000]\n",
            "loss: 0.902212  [19200/60000]\n",
            "loss: 0.803555  [25600/60000]\n",
            "loss: 0.808206  [32000/60000]\n",
            "loss: 0.882093  [38400/60000]\n",
            "loss: 0.841384  [44800/60000]\n",
            "loss: 0.854880  [51200/60000]\n",
            "loss: 0.804598  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.3%, Avg loss: 0.815688 \n",
            "\n",
            "loss: 0.836610  [    0/60000]\n",
            "loss: 0.903517  [ 6400/60000]\n",
            "loss: 0.680135  [12800/60000]\n",
            "loss: 0.865732  [19200/60000]\n",
            "loss: 0.772817  [25600/60000]\n",
            "loss: 0.769767  [32000/60000]\n",
            "loss: 0.849652  [38400/60000]\n",
            "loss: 0.816881  [44800/60000]\n",
            "loss: 0.822915  [51200/60000]\n",
            "loss: 0.775924  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.7%, Avg loss: 0.785375 \n",
            "\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 Load 및 Save\n"
      ],
      "metadata": {
        "id": "ipKOSqWrdgnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"quick_start_pth\"\n",
        "torch.save(model.state_dict(), model_path) # saved object: state_dict => , file path \n",
        "print(f\"saved to {model_path}\")  # save process?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ_rhCw1dbci",
        "outputId": "c5e3f883-a643-4169-ba89-2cc59c69a501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved to quick_start_pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EapEX0GUdk35",
        "outputId": "b6aef722-93e7-46e3-d143-f11ca10d8e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()  # turn mode to test time \n",
        "x, y = test_data[0][0], test_data[0][1] # (image, target) where target is index of the target class\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual=classes[pred[0].argmax(0)], classes[y] # see above classes table : QUESTION // constant for dimension 0 for vector ways\n",
        "\n",
        "    print(pred[0])\n",
        "    print(\"==========================\")\n",
        "\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcVzjOk5gb2V",
        "outputId": "51a207a8-5c04-40db-c21f-cadff81da28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.4465, -2.6904, -1.0338, -1.9402, -0.9676,  2.4919, -1.2347,  2.7351,\n",
            "         1.8703,  3.1323])\n",
            "==========================\n",
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    }
  ]
}